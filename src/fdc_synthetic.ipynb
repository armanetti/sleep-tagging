{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import fdc\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sleep_stage_function as ssf\n",
    "fdc=reload(fdc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Simple random process with coupled Oersten-Uhlembeck "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 83\n",
    "x = np.random.randn(N, 1000) / np.sqrt(N)\n",
    "np.shape(np.triu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 1\n",
    "frequency = 250\n",
    "n_chunks = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = fdc.correlation_freq(x,time_step,frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(s) #matrixe di correlazione integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.diag(s).real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sii = []\n",
    "for freq in np.linspace(1,50,1000):\n",
    "    s = fdc.correlation_freq(x,time_step,freq)\n",
    "    smean = np.mean(np.diag(s).real)\n",
    "    #print(smean)\n",
    "    sii.append(smean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sii)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_OU(J, T=20000, dt=1, sigma=1.0, g=None):\n",
    "    \"\"\"\n",
    "    Generate multivariate Ornstein-Uhlenbeck (OU) process.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : number of nodes\n",
    "    T : number of time points\n",
    "    dt : timestep in seconds\n",
    "    g : global coupling (scales J)\n",
    "    sigma : noise amplitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : array shape (N, T)\n",
    "        OU time series ready to use with correlation_freq()\n",
    "    \"\"\"\n",
    "    # Random Gaussian connectivity (consistent with the paper's theory)\n",
    "\n",
    "    N = len(J)\n",
    "\n",
    "    if g == None:\n",
    "        lambdamax = np.max(np.linalg.eigvals(J))\n",
    "        g = 1/lambdamax - 0.1\n",
    "    \n",
    "    X = np.zeros((N, T))\n",
    "    noise_scale = np.sqrt(sigma * dt)\n",
    "\n",
    "    for t in range(T-1):\n",
    "        drift = (-X[:, t] + g * J @ X[:, t])\n",
    "        noise = noise_scale * np.random.randn(N) \n",
    "        X[:, t+1] = X[:, t] + dt * drift + noise\n",
    "\n",
    "    # Removing transient (optional)\n",
    "    return X#[:, 5000:]   # discard first 5k samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_OU(J, T=20000, dt=0.01, sigma=1.0, g=None, burn_in=0):\n",
    "    \"\"\"\n",
    "    Generate multivariate Ornstein-Uhlenbeck (OU) process.\n",
    "    \n",
    "    Implements:\n",
    "        dx_i/dt = -x_i + g * sum_j J_ij * x_j + sigma * xi_i(t)\n",
    "    \n",
    "    where xi_i(t) is white noise with <xi_i(t)xi_j(s)> = delta_ij * delta(t-s)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    J : np.ndarray, shape (N, N)\n",
    "        Connectivity matrix\n",
    "    T : int\n",
    "        Number of time points\n",
    "    dt : float\n",
    "        Time step (in seconds). Default: 0.01\n",
    "    sigma : float\n",
    "        Noise amplitude. Default: 1.0\n",
    "    g : float, optional\n",
    "        Global coupling strength (scales J).\n",
    "        If None, sets g = 1/lambda_max - 0.1 (near critical)\n",
    "    burn_in : int\n",
    "        Number of initial time steps to discard (transient removal)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X : np.ndarray, shape (N, T - burn_in)\n",
    "        OU time series ready to use with correlation_freq()\n",
    "    \"\"\"\n",
    "    N = len(J)\n",
    "    \n",
    "    # Set coupling strength\n",
    "    if g is None:\n",
    "        # Near the edge of instability\n",
    "        lambdamax = np.max(np.real(np.linalg.eigvals(J)))\n",
    "        g = 1.0 / lambdamax - 0.1\n",
    "        print(f\"Auto-setting g = {g:.4f} (lambda_max = {lambdamax:.4f})\")\n",
    "    \n",
    "    # Initialize\n",
    "    X = np.zeros((N, T))\n",
    "    X[:, 0] = np.random.randn(N) * 0.1  # Small random initial condition\n",
    "    \n",
    "    # Euler-Maruyama integration\n",
    "    noise_scale = sigma * np.sqrt(dt)  \n",
    "    \n",
    "    for t in range(T - 1):\n",
    "        # Deterministic part\n",
    "        drift = -X[:, t] + g * (J @ X[:, t])\n",
    "        \n",
    "        # Stochastic part\n",
    "        noise = noise_scale * np.random.randn(N)\n",
    "        \n",
    "        # Update\n",
    "        X[:, t + 1] = X[:, t] + dt * drift + noise\n",
    "    \n",
    "    # Remove transient if requested\n",
    "    if burn_in > 0:\n",
    "        return X[:, burn_in:]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## random example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 83\n",
    "A = np.random.randn(N, N) / np.sqrt(N)\n",
    "J = (A + A.T) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 128\n",
    "T = tp*30\n",
    "dt=1/tp\n",
    "x = generate_OU(J, T, dt, sigma=2, g=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape = (N, T)   # Your OU data\n",
    "dt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.linspace(0.0001, 100, 1000) #np.logspace(-3, 2., 50)  \n",
    "omegas = 2 * np.pi * freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_freq = np.zeros((N, N, len(freqs)), dtype=complex)\n",
    "S_ii = []\n",
    "\n",
    "for i, f in enumerate(freqs):\n",
    "    cif = fdc.correlation_freq(\n",
    "        x,\n",
    "        time_step=dt,\n",
    "        frequency=f,\n",
    "        n_chunks=10,          # important for unbiased estimator\n",
    "        corr_type=\"covariance\"\n",
    "    )\n",
    "    C_freq[:, :, i] = cif\n",
    "    S_ii.append(np.mean(np.diag(cif)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(freqs,S_ii)\n",
    "plt.plot(freqs,1/omegas**2)\n",
    "#plt.xlim(10e0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Block diagonal case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 80\n",
    "\n",
    "tp = 128\n",
    "T = tp * 1000  # = 12800 time steps (~100 s con dt=1/128)\n",
    "dt = 1/tp\n",
    "burn_in = tp * 100  # Rimuovi transiente\n",
    "\n",
    "sigma = 1\n",
    "\n",
    "#freqs = np.linspace(1e-3, 100, 1000) #\n",
    "freqs = np.logspace(-3, 1, 1000)  \n",
    "omegas = 2 * np.pi * freqs\n",
    "\n",
    "\n",
    "A = np.random.randn(int(N/2), int(N/2)) / np.sqrt(int(N/2))\n",
    "J = (A + A.T) / 2\n",
    "#J = J - np.diag(np.diag(J))  # remove self-connections\n",
    "alpha = 1\n",
    "\n",
    "if alpha < 1: \n",
    "    g = 1/(2*alpha) - 0.1\n",
    "else:\n",
    "    g = 1/(2*alpha) -0.1\n",
    "beta = 5\n",
    "\n",
    "print(\"g:\", g)\n",
    "\n",
    "\n",
    "omega_peak = 2 * beta * g / alpha  # In rad/s\n",
    "f_peak = omega_peak / (2 * np.pi)  # In Hz\n",
    "\n",
    "print(\"f_peak (Hz):\", f_peak)   \n",
    "\n",
    "W = np.block([\n",
    "        [ alpha * J,  -beta * J ],\n",
    "        [ beta  * J,   alpha * J ]\n",
    "    ])\n",
    "\n",
    "# generate process\n",
    "x = generate_OU(W, T, dt, sigma=sigma, g=g, burn_in=burn_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_freq = np.zeros((N, N, len(freqs)), dtype=complex)\n",
    "S_ii = []\n",
    "\n",
    "for i, f in enumerate(freqs):\n",
    "    cif = fdc.correlation_freq(\n",
    "        x,\n",
    "        time_step=dt,\n",
    "        frequency=f,\n",
    "        n_chunks=10,          # important for unbiased estimator\n",
    "        corr_type=\"covariance\"\n",
    "    )\n",
    "    C_freq[:, :, i] = cif\n",
    "    S_ii.append(np.mean(np.diag(cif)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(freqs,S_ii)\n",
    "#plt.plot(freqs,1/omegas**2*10e12) \n",
    "plt.axvline(f_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(S_ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs[np.argmax(S_ii)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta/(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*g*beta/alpha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
